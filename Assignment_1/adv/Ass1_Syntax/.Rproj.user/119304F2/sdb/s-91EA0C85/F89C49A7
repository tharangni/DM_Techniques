{
    "collab_server" : "",
    "contents" : "######################################\n# HELPER FUNCTIONS\n\n#This syntax: \n# - splitdata_id - function for splitting the data based on ID (ordered)\n# - forecast_ARIMA_auto - function for ARIMA automatica selection of parameters\n# - forecast_ARIMA_manual - function for ARIMA automatica selection of parameters\n# - Performance - function for evaluating model\n######################################\n\n\nsplitdata_id <- function (dataset) {\n  # Function split the data into training, validation and test set (ordered by time) \n  # for different id's. \n  #\n  # INPUT: Dataset with variable id\n  # OUTPUT: \n  \n  datasetTrain <- c()\n  datasetValid <- c()\n  datasetTest <- c()\n  \n  #For each user \n  for (user_id in unique(dataset$id)) {\n  \n    #Create temporary dataset\n    df <- dataset[which(dataset$id == user_id), ]\n    \n    # Fixed Input - Set the fractions of the dataframe you want to split into training, \n    # validation, and test.\n    fractionTraining   <- 0.70\n    fractionValidation <- 0.15\n    fractionTest       <- 0.15\n    \n    # Compute sample sizes.\n    sampleSizeTraining   <- floor(fractionTraining   * nrow(df))\n    sampleSizeValidation <- floor(fractionValidation * nrow(df))\n    sampleSizeTest       <- floor(fractionTest       * nrow(df))\n    \n    # Create the randomly-sampled indices for the dataframe. Use setdiff() to\n    # avoid overlapping subsets of indices.\n    total_indices      <- seq.int(nrow(df))\n    indicesTraining    <- total_indices[1: sampleSizeTraining]\n    indicesNotTraining <- setdiff(seq_len(nrow(df)), indicesTraining)\n    indicesValidation  <- indicesNotTraining[1: sampleSizeValidation]\n    indicesTest        <- setdiff(indicesNotTraining, indicesValidation)\n\n    # Create the three dataframes for training, validation and test.\n    dfTraining   <- df[indicesTraining, ]\n    dfValidation <- df[indicesValidation, ]\n    dfTest       <- df[indicesTest, ]\n    \n    # Append the tables to output\n    datasetTrain <- rbind(datasetTrain, dfTraining)\n    datasetValid <- rbind(datasetValid, dfValidation)\n    datasetTest <- rbind(datasetTest, dfTest)\n  }\n  \n  return(list(datasetTrain, datasetValid, datasetTest ))\n  \n}\n\n\n\n##########################################################\n\n##########################################################\n\n\nforecast_ARIMA_auto <- function(trainData, testData) {\n  #function trains a time series model per ID \n  #INPUT: training dataset \n  #Output: Test dataset with extra column with predicted values\n  \n  #initialise c() with forecasted data\n  finalForecast <- c()\n  totalDays <- 0 \n  \n  for (user_id in unique(trainData$id)) {\n    \n    #Subset user data\n    dfUser <- trainData[which(trainData$id == user_id), c(\"date\", \"interp_mood\")]\n    \n    #Create a time series frame\n    dfUser <- ts(data =  as.data.frame(dfUser), start = c(1))\n    \n    #Create ARIMA model\n    model <- auto.arima(dfUser[, 2])\n    \n    #Get test data for specific user\n    dfUserTest <- testData[which(testData$id == user_id), c(\"interp_mood\")]\n    \n    #Define how many forecast point necessary\n    f_days <- dim(dfUserTest)[1]\n    totalDays <- totalDays + f_days\n    \n    #\n    print (paste(\"Forecasting for ID\", user_id, \"for\",  f_days, \"days\"))\n    #\n    \n    #Forecast model for length of test data (f_days)\n    forecastModel <- forecast(object = model, h = f_days)\n    \n    #unpack forecasts\n    temp <- c()\n    for (i in c(1:length(as.numeric(forecastModel$mean)))) {\n      temp <- rbind(temp, as.numeric(forecastModel$mean)[[i]])\n    }\n    \n    #Concatenate forecast to finalForecast\n    finalForecast <- rbind(finalForecast, temp)\n    \n  }\n  \n  #Append new forecasted values to testData\n  testData$forecast_mood <- finalForecast\n  \n  #\n  print(paste(\"Total forecasted days across all IDs\", totalDays))\n  #\n  \n  return(testData)\n}\n\n\n##########################################################\n\n##########################################################\n\n\nforecast_ARIMA_manual <- function(trainData, testData) {\n  #function trains a time series model per ID \n  #INPUT: training dataset \n  #Output: Test dataset with extra column with predicted values\n  \n  #initialise c() with forecasted data\n  finalForecast <- c()\n  totalDays <- 0 \n  \n  for (user_id in unique(trainData$id)) {\n    \n    #Subset user data\n    dfUser <- trainData[which(trainData$id == user_id), c(\"date\", \"interp_mood\")]\n    \n    #Create a time series frame\n    dfUser <- ts(data =  as.data.frame(dfUser), start = c(1))\n    \n    #run ARIMA iterations model\n    bestAIC <- 99999999\n    \n    for(p in 0:2){\n      for(d in 0:1){\n        for(q in 0:2){\n          \n          #run ARIMA\n          model <- arima(dfUser[, 2], order = c(p,d,q), method=\"ML\") \n          tempAIC <- model$aic\n          \n          #pick best model by checking low AIC\n          if (tempAIC < bestAIC)\n          {\n            bestAIC <- tempAIC\n            bestModel <- model\n            \n            \n          }\n          \n        }\n      }\n    }\n    \n    #print (bestModel)\n    \n    #Get test data for specific user\n    dfUserTest <- testData[which(testData$id == user_id), c(\"interp_mood\")]\n    \n    #Define how many forecast point necessary\n    f_days <- dim(dfUserTest)[1]\n    totalDays <- totalDays + f_days\n    \n    #\n    print (paste(\"Forecasting for ID\", user_id, \"for\",  f_days, \"days\"))\n    #\n    \n    #Forecast BestModel for length of test data (f_days)\n    forecastModel <- forecast(object = bestModel, h = f_days)\n    \n    #unpack forecasts\n    temp <- c()\n    for (i in c(1:length(as.numeric(forecastModel$mean)))) {\n      temp <- rbind(temp, as.numeric(forecastModel$mean)[[i]])\n    }\n    \n    #Concatenate forecast to finalForecast\n    finalForecast <- rbind(finalForecast, temp)\n    \n  }\n  \n  #Append new forecasted values to testData\n  testData$forecast_mood <- finalForecast\n  \n  #\n  print(paste(\"Total forecasted days across all IDs\", totalDays))\n  #\n  \n  return(testData)\n}\n\n\n##########################################################\n\n\nlinearRegression_perID <- function (trainData, testData) {\n        # function trains a model per ID\n        # i/p: training dataset\n        # o/p: test dataset + column with predicted values\n  \n  predicts <- c()\n  print(\"Hello\")\n  for (user_id in unique(trainData$id)) {\n  \n          print (user_id)\n          dfUser <- trainData[which(trainData$id == user_id), ]\n          dfUser_test <- testData[which(testData$id == user_id), ]\n          dfUser$id <- NULL\n          \n          \n          dfUser_test_x = subset(dfUser_test, select = -c(interp_mood, id))\n          #dfUser_test_y = dfUser_test$interp_mood\n          \n          # create a linear regression model\n          \n          dfUser <- na.omit(dfUser)\n          lm_Model <- lm(formula = interp_mood ~ ma7_interp_mood + ma2_interp_valence +\n                         lag_open_count + ma5_agg_call + lag_sms,\n                         data = dfUser)\n           \n          lm_Model <- step(lm_Model)\n          predictMood <- predict(lm_Model, dfUser_test_x)\n          \n          temp <- c()\n          for (i in c(1:length(as.numeric(predictMood)))) {\n            temp <- rbind(temp, as.numeric(predictMood)[[i]])\n          }\n          \n          #Concatenate prediction\n          predicts <- rbind(predicts, temp)\n  \n        \n  }\n  predicts <- as.vector(t(predicts))\n  \n  testData$predicted_RegressionUser <- predicts\n  \n  return(testData)\n}\n\n\n##########################################################\n\n##########################################################\n\n\nPerformance <- function(actual, predicted, b){\n  #Function checks if predicted value is within a certain boundary.\n  #if it within the boundary its a one, if not, its a zero.\n  \n  boundary <- b\n  \n  temp <- (actual- predicted)^2\n  \n  accurate <- ifelse(temp <= boundary^2,\n                     accurate <- 1, \n                     accurate <- 0)\n\n  return(sum(accurate) / length(accurate))\n  \n}\n\n##########################################################\n\n##########################################################\n\nRegressionPerVariable <- function(trainingSet){\n  \n  #initialise return data frame\n  RegressionPerVariable <- c()\n  \n  for (variable in names(trainingSet)){\n    \n    print (variable)\n    \n    #skip mood variable - duh\n    if (variable == \"interp_mood\"){next}\n    \n    #3: Train Model\n    formula = as.formula(paste(\"interp_mood ~ \", variable))\n    model = lm(formula, data = trainingSet)\n    \n    #4: Predict on validation data\n    pred = predict(model, valid_x)\n    \n    #5.1: Evaluate Model metrics on Validation\n    temp_rmse <- rmse(actual = valid_y, predicted = pred)\n    temp_performance <- Performance(actual = valid_y, predicted = pred, 0.5)\n    \n    \n    \n    \n    # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n    # #SVM MODEL\n    # formula = as.formula(paste(\"interp_mood ~ \", variable))\n    # model = svm(formula, data = trainingSet)\n    # \n    # #4: Predict on validation data\n    # pred = predict(model, valid_x)\n    # \n    # #5.1: Evaluate Model metrics on Validation\n    # svm_temp_rmse <- rmse(actual = valid_y, predicted = pred)\n    # svm_temp_performance <- Performance(actual = valid_y, predicted = pred, 0.5)\n    # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n    \n    #temp_modelMetrics <- cbind(variable, temp_rmse, temp_performance, svm_temp_rmse, svm_temp_performance )\n    temp_modelMetrics <- cbind(variable, temp_rmse, temp_performance)\n    RegressionPerVariable <- rbind(RegressionPerVariable, temp_modelMetrics)\n  }\n  \n  return(as.data.frame(RegressionPerVariable))\n}\n\n##########################################################\n\n\n\n\nTransformations <-function(trainingSet, loopnames) {\n  for (variable in loopnames){\n    if (variable == \"id\") {next}\n    if (variable == \"interp_mood\") {next}\n    \n    print(variable)\n    \n    trainingSet[paste(variable, \"_squared\", sep = \"\")] <- trainingSet[variable]**2 \n    trainingSet[paste(variable, \"_cubed\", sep = \"\")] <- trainingSet[variable]**3 \n    #trainingSet[paste(variable, \"_log\", sep = \"\")] <- log(trainingSet[variable])\n    \n  }\n  return(trainingSet)\n}\n\n\nCoTransformations <-function(trainingSet, loopnames) {\n  \n  for (variable in loopnames){\n    \n    if (variable == \"id\") {next}\n    if (variable == \"interp_mood\") {next}\n    if (variable == \"lag_mood\") {next}\n    if (variable == \"ma2_interp_mood\") {next}\n    if (variable == \"ma5_interp_mood\") {next}\n    if (variable == \"ma7_interp_mood\") {next}\n    \n    print(variable)\n    \n    for (variable2 in loopnames){\n      if (variable2 == \"id\") {next}\n      if (variable2 == \"interp_mood\") {next}\n      if (variable == \"ma2_interp_mood\") {next}\n      if (variable == \"ma5_interp_mood\") {next}\n      if (variable == \"ma7_interp_mood\") {next}\n      \n      print(paste(variable, variable2))\n      #trainingSet[paste(variable, \"_\", variable2, \"_sum\", sep = \"\" )] <- trainingSet[variable] + trainingSet[variable2]\n      trainingSet[paste(variable, \"_\", variable2, \"_multiply\", sep = \"\" )] <- trainingSet[variable] * trainingSet[variable2]\n      #trainingSet[paste(variable, \"_\", variable2, \"_ratio\", sep = \"\" )] <- trainingSet[variable] / trainingSet[variable2]\n      \n    }\n  }\n  return(trainingSet)\n}\n",
    "created" : 1524123778872.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "11|36|60|0|\n130|56|206|0|\n263|46|277|0|\n",
    "hash" : "1928386670",
    "id" : "F89C49A7",
    "lastKnownWriteTime" : 1524142388,
    "last_content_update" : 1524142388623,
    "path" : "~/Desktop/Data Mining Techniques/DM_Techniques/Assignment_1/adv/Ass1_Syntax/Helper_Functions.R",
    "project_path" : "Helper_Functions.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}